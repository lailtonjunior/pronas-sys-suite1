#!/bin/bash
set -e

echo "ğŸ¤– CONFIGURANDO MELHOR MODELO GEMINI"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

cd /root/pronas-sys-suite1

# Criar text_agent.py otimizado
cat > backend/app/ai/agents/text_agent.py << 'AGENTEOF'
from typing import Dict, List
import google.generativeai as genai
from app.config import settings
from app.ai.rag.embeddings import generate_embedding
from app.ai.rag.vectorstore import search_similar_cases
import asyncio
import logging

logger = logging.getLogger(__name__)
genai.configure(api_key=settings.GEMINI_API_KEY)

async def suggest_text(field_name: str, field_context: Dict, project_context: Dict) -> Dict:
    """Agente de sugestÃ£o de texto usando RAG + Gemini 2.5"""
    
    try:
        # 1. Buscar casos similares (RAG)
        query = f"{project_context.get('field', '')} {project_context.get('priority_area', '')} {field_name}"
        query_vector = generate_embedding(query)
        similar_cases = search_similar_cases(query_vector, limit=5)
        
        # 2. Montar contexto RAG
        rag_context = ""
        if similar_cases:
            rag_context = "\n\n".join([
                f"ğŸ“‹ Caso Aprovado {i+1} (Score: {case.score:.2f}):\n{case.payload.get('summary', case.payload.get('text', ''))[:400]}"
                for i, case in enumerate(similar_cases[:3])
            ])
        
        # 3. Montar prompt otimizado
        prompt = f"""VocÃª Ã© um especialista em elaboraÃ§Ã£o de projetos PRONAS/PCD (Programa Nacional de Apoio Ã  AtenÃ§Ã£o da SaÃºde da Pessoa com DeficiÃªncia) conforme Portaria GM/MS nÂº 8.031/2025.

ğŸ“Œ CAMPO A PREENCHER: {field_name}

ğŸ¥ CONTEXTO DO PROJETO:
- TÃ­tulo: {project_context.get('title', 'NÃ£o informado')}
- Ãrea: {project_context.get('field', 'prestacao_servicos_medico_assistenciais')}
- Ãrea PrioritÃ¡ria: {project_context.get('priority_area', 'ReabilitaÃ§Ã£o')}
- InstituiÃ§Ã£o: {project_context.get('institution_name', 'NÃ£o informada')}

{"ğŸ“š REFERÃŠNCIAS DE PROJETOS APROVADOS:" if rag_context else ""}
{rag_context}

ğŸ“ INSTRUÃ‡Ã•ES:
1. Gere um texto profissional e tÃ©cnico para o campo "{field_name}"
2. Mencione conformidade com a Portaria GM/MS nÂº 8.031/2025
3. Use terminologia tÃ©cnica da Ã¡rea de saÃºde e reabilitaÃ§Ã£o
4. Inclua indicadores mensurÃ¡veis quando aplicÃ¡vel
5. Seja especÃ­fico e objetivo
6. Limite: 150-200 palavras

Gere APENAS o conteÃºdo sugerido, sem explicaÃ§Ãµes adicionais."""

        # 4. Tentar gemini-2.5-flash primeiro (mais rÃ¡pido)
        try:
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = await asyncio.wait_for(
                asyncio.to_thread(model.generate_content, prompt),
                timeout=10.0
            )
            model_used = 'gemini-2.5-flash'
            
        except Exception as e:
            # Fallback para gemini-2.5-pro se flash falhar
            logger.warning(f"gemini-2.5-flash falhou: {e}. Tentando gemini-2.5-pro...")
            model = genai.GenerativeModel('gemini-2.5-pro')
            response = await asyncio.wait_for(
                asyncio.to_thread(model.generate_content, prompt),
                timeout=15.0
            )
            model_used = 'gemini-2.5-pro'
        
        # 5. Processar resposta
        suggestion_text = response.text.strip()
        
        # Limpar formataÃ§Ã£o markdown se houver
        suggestion_text = suggestion_text.replace('**', '').replace('##', '')
        
        return {
            "suggestion": suggestion_text,
            "confidence": 0.90 if len(similar_cases) >= 3 else 0.75 if len(similar_cases) > 0 else 0.60,
            "references": [
                {"id": str(c.id), "score": float(c.score), "title": c.payload.get('title', '')[:50]} 
                for c in similar_cases[:3]
            ],
            "similar_cases_count": len(similar_cases),
            "model_used": model_used
        }
        
    except asyncio.TimeoutError:
        logger.error("Timeout ao gerar sugestÃ£o")
        return {
            "suggestion": "â±ï¸ Tempo limite excedido. A IA estÃ¡ processando muitos pedidos. Tente novamente em alguns segundos.",
            "confidence": 0.0,
            "error": "timeout"
        }
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Erro ao gerar sugestÃ£o: {error_msg}")
        
        # Se houver casos similares, retornar pelo menos isso
        if similar_cases and len(similar_cases) > 0:
            best_case = similar_cases[0]
            return {
                "suggestion": f"ğŸ“š Baseado em caso similar aprovado:\n\n{best_case.payload.get('summary', '')[:400]}",
                "confidence": 0.5,
                "references": [{"id": str(best_case.id), "score": float(best_case.score)}],
                "similar_cases_count": len(similar_cases),
                "fallback": "rag_only"
            }
        
        return {
            "suggestion": "âŒ Erro ao processar solicitaÃ§Ã£o. Verifique a conexÃ£o e tente novamente.",
            "confidence": 0.0,
            "error": error_msg[:100]
        }
AGENTEOF

echo "âœ… text_agent.py configurado com gemini-2.5-flash + fallback"

echo ""
echo "ğŸ”„ Reiniciando backend..."
docker compose restart backend

echo ""
echo "â³ Aguardando 15 segundos..."
sleep 15

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§ª TESTANDO IA COM GEMINI 2.5"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Teste 1: Verificar modelo
echo "1ï¸âƒ£ Testando conexÃ£o Gemini 2.5:"
docker compose exec -T backend python3 << 'TEST1'
import google.generativeai as genai
import os

genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

try:
    model = genai.GenerativeModel('gemini-2.5-flash')
    response = model.generate_content("Diga apenas: OK")
    print(f"   âœ… Gemini 2.5 Flash: {response.text.strip()}")
except Exception as e:
    print(f"   âŒ Erro: {e}")
TEST1

echo ""
echo "2ï¸âƒ£ Testando endpoint /ai/suggest com projeto real:"
echo ""

RESPONSE=$(curl -s -X POST http://localhost:8000/api/ai/suggest \
  -H "Content-Type: application/json" \
  -d '{
    "field_name": "justificativa",
    "field_context": {
      "label": "Justificativa do Projeto"
    },
    "project_context": {
      "title": "AMPLIANDO ATENDIMENTOS DE FISIOTERAPIA NA APAE DE COLINAS",
      "field": "prestacao_servicos_medico_assistenciais",
      "institution_name": "APAE de Colinas do Tocantins",
      "priority_area": "ReabilitaÃ§Ã£o FÃ­sica e Funcional"
    }
  }')

echo "ğŸ“„ SUGESTÃƒO GERADA PELA IA:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "$RESPONSE" | jq -r '.suggestion' 2>/dev/null | fold -w 70 -s
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸ“Š MÃ‰TRICAS:"
echo "   â€¢ ConfianÃ§a: $(echo "$RESPONSE" | jq -r '.confidence')"
echo "   â€¢ Casos similares: $(echo "$RESPONSE" | jq -r '.similar_cases_count')"
echo "   â€¢ Modelo usado: $(echo "$RESPONSE" | jq -r '.model_used')"

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ‰ IA CONFIGURADA COM SUCESSO!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ï¿½ï¿½ AGORA TESTE NO FRONTEND:"
echo "   http://72.60.255.80:3000/projeto/6/editar"
echo ""
echo "ğŸ’¡ DICAS:"
echo "   â€¢ Tempo de resposta: 2-5 segundos"
echo "   â€¢ Qualidade: Excelente (Gemini 2.5)"
echo "   â€¢ Se travar, aguarde 10s e tente novamente"
echo ""

